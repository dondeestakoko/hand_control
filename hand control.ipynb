{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.48  Python-3.11.0 torch-2.2.2+cpu CPU (Intel Core(TM) i5-7200U 2.50GHz)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0mtask=detect, mode=train, model=yolov8n.pt, data=data.yaml, epochs=50, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=4, project=None, name=train11, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs\\detect\\train11\n",
      "Overriding model.yaml nc=80 with nc=7\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
      " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
      " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 22        [15, 18, 21]  1    752677  ultralytics.nn.modules.head.Detect           [7, [64, 128, 256]]           \n",
      "Model summary: 225 layers, 3,012,213 parameters, 3,012,197 gradients, 8.2 GFLOPs\n",
      "\n",
      "Transferred 319/355 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs\\detect\\train11', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\ironman project\\train\\labels... 165 images, 0 backgrounds, 0 corrupt: 100%|██████████| 165/165 [00:01<00:00, 106.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: C:\\ironman project\\train\\labels.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\ironman project\\test\\labels... 23 images, 0 backgrounds, 0 corrupt: 100%|██████████| 23/23 [00:00<00:00, 95.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: C:\\ironman project\\test\\labels.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs\\detect\\train11\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000909, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added \n",
      "Image sizes 640 train, 640 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1mruns\\detect\\train11\u001b[0m\n",
      "Starting training for 50 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       1/50         0G      1.587      4.127      1.796         10        640: 100%|██████████| 11/11 [02:35<00:00, 14.14s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:05<00:00,  5.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         23         23    0.00647          1       0.49      0.285\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       2/50         0G      1.025      3.581      1.278          8        640: 100%|██████████| 11/11 [02:21<00:00, 12.87s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:04<00:00,  4.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         23         23    0.00742          1      0.527      0.418\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       3/50         0G     0.9509      2.906      1.217         11        640: 100%|██████████| 11/11 [02:23<00:00, 13.02s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:04<00:00,  4.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         23         23    0.00628          1      0.664       0.54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       4/50         0G     0.9071      2.432      1.194         12        640: 100%|██████████| 11/11 [02:19<00:00, 12.66s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:04<00:00,  4.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         23         23    0.00574          1      0.732      0.595\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       5/50         0G     0.9464      2.009      1.205         14        640: 100%|██████████| 11/11 [02:19<00:00, 12.67s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:04<00:00,  4.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         23         23          1      0.139      0.829      0.677\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       6/50         0G      0.886      1.861      1.169         14        640: 100%|██████████| 11/11 [02:19<00:00, 12.69s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:04<00:00,  4.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         23         23      0.768      0.803      0.995      0.773\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       7/50         0G      0.915      1.802      1.186          8        640: 100%|██████████| 11/11 [02:20<00:00, 12.73s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:04<00:00,  4.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         23         23      0.871      0.977      0.995      0.824\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       8/50         0G     0.8767      1.625      1.123          9        640: 100%|██████████| 11/11 [02:20<00:00, 12.78s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:05<00:00,  5.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         23         23      0.887      0.979      0.995      0.815\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       9/50         0G     0.8394       1.47      1.091          9        640: 100%|██████████| 11/11 [02:18<00:00, 12.55s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:04<00:00,  4.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         23         23       0.96      0.755      0.995      0.771\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      10/50         0G      0.917       1.61      1.162          7        640: 100%|██████████| 11/11 [02:20<00:00, 12.79s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:04<00:00,  4.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         23         23      0.911          1      0.995      0.744\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      11/50         0G     0.8049      1.426      1.083          9        640: 100%|██████████| 11/11 [02:22<00:00, 12.99s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:04<00:00,  4.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         23         23      0.888      0.982      0.995      0.808\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      12/50         0G     0.7962      1.328      1.074         14        640: 100%|██████████| 11/11 [02:21<00:00, 12.86s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:04<00:00,  4.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         23         23      0.945      0.929      0.995      0.809\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      13/50         0G     0.8026      1.308      1.075         11        640: 100%|██████████| 11/11 [02:21<00:00, 12.89s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:04<00:00,  4.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         23         23      0.912      0.972      0.995      0.799\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      14/50         0G     0.7744      1.202      1.056         17        640: 100%|██████████| 11/11 [02:19<00:00, 12.66s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:04<00:00,  4.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         23         23       0.95      0.954      0.995      0.825\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      15/50         0G     0.7873      1.226      1.042         12        640: 100%|██████████| 11/11 [02:20<00:00, 12.76s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:04<00:00,  4.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         23         23      0.937          1      0.995      0.806\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      16/50         0G     0.7757      1.213      1.055         14        640: 100%|██████████| 11/11 [02:18<00:00, 12.58s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:04<00:00,  4.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         23         23      0.949      0.975      0.995      0.814\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      17/50         0G     0.8219       1.26      1.089         14        640: 100%|██████████| 11/11 [02:19<00:00, 12.66s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:04<00:00,  4.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         23         23      0.901      0.936      0.987      0.779\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      18/50         0G     0.7934      1.145      1.044         13        640: 100%|██████████| 11/11 [02:19<00:00, 12.71s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:04<00:00,  4.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         23         23      0.971          1      0.995      0.804\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      19/50         0G     0.7701      1.166      1.061         13        640: 100%|██████████| 11/11 [02:19<00:00, 12.66s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:05<00:00,  5.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         23         23        0.9      0.978      0.995       0.82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      20/50         0G     0.7132      1.065      1.011         15        640: 100%|██████████| 11/11 [02:25<00:00, 13.25s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:04<00:00,  4.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         23         23      0.979          1      0.995       0.83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      21/50         0G      0.733      1.102      1.029          7        640: 100%|██████████| 11/11 [02:19<00:00, 12.67s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:04<00:00,  4.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         23         23      0.977          1      0.995       0.81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      22/50         0G     0.7329      1.114      1.032         10        640: 100%|██████████| 11/11 [02:20<00:00, 12.79s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:04<00:00,  4.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         23         23      0.973          1      0.995      0.803\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      23/50         0G     0.7198      1.092      1.021         11        640: 100%|██████████| 11/11 [02:19<00:00, 12.66s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:04<00:00,  4.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         23         23      0.968          1      0.995      0.813\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      24/50         0G       0.72      1.051       1.04          8        640: 100%|██████████| 11/11 [02:19<00:00, 12.66s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:04<00:00,  4.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         23         23      0.968          1      0.995      0.842\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      25/50         0G       0.72      1.014      1.037         13        640: 100%|██████████| 11/11 [02:19<00:00, 12.67s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:04<00:00,  4.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         23         23      0.981          1      0.995      0.817\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      26/50         0G     0.6485     0.9429     0.9815         12        640: 100%|██████████| 11/11 [02:19<00:00, 12.71s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:04<00:00,  4.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         23         23      0.955          1      0.995      0.844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      27/50         0G     0.6563     0.9648     0.9641         15        640: 100%|██████████| 11/11 [02:17<00:00, 12.49s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:04<00:00,  4.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         23         23      0.929      0.999      0.995      0.829\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      28/50         0G      0.629     0.8915       0.98         13        640: 100%|██████████| 11/11 [02:19<00:00, 12.67s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:04<00:00,  4.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         23         23      0.936      0.992      0.995      0.802\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      29/50         0G     0.6704      0.943      1.004          8        640: 100%|██████████| 11/11 [02:19<00:00, 12.68s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:04<00:00,  4.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         23         23      0.932       0.99      0.995      0.829\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      30/50         0G     0.6361     0.8671      0.972         12        640: 100%|██████████| 11/11 [02:20<00:00, 12.78s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:04<00:00,  4.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         23         23      0.973          1      0.995      0.835\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      31/50         0G      0.653     0.8925     0.9896         15        640: 100%|██████████| 11/11 [02:18<00:00, 12.62s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:04<00:00,  4.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         23         23       0.96      0.994      0.995      0.821\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      32/50         0G     0.6251     0.8635      0.985         10        640: 100%|██████████| 11/11 [02:20<00:00, 12.79s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:04<00:00,  4.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         23         23      0.934      0.994      0.995      0.826\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      33/50         0G     0.5932     0.8245     0.9692         13        640: 100%|██████████| 11/11 [02:17<00:00, 12.54s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:04<00:00,  4.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         23         23      0.937      0.997      0.995      0.803\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      34/50         0G     0.5804     0.7808     0.9721         14        640: 100%|██████████| 11/11 [02:19<00:00, 12.68s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:04<00:00,  4.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         23         23      0.966          1      0.995      0.822\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      35/50         0G     0.5996     0.7935     0.9651         11        640: 100%|██████████| 11/11 [02:20<00:00, 12.78s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:04<00:00,  4.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         23         23      0.981          1      0.995      0.816\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      36/50         0G     0.6089      0.813     0.9726          7        640: 100%|██████████| 11/11 [02:21<00:00, 12.84s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:04<00:00,  4.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         23         23       0.98          1      0.995      0.823\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      37/50         0G     0.5639     0.7698     0.9411         11        640: 100%|██████████| 11/11 [02:20<00:00, 12.80s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:04<00:00,  4.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         23         23      0.974          1      0.995      0.826\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      38/50         0G     0.5598     0.7797     0.9428         15        640: 100%|██████████| 11/11 [02:19<00:00, 12.68s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:04<00:00,  4.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         23         23      0.972          1      0.995      0.824\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      39/50         0G      0.544     0.7274       0.93         12        640: 100%|██████████| 11/11 [02:20<00:00, 12.77s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:04<00:00,  4.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         23         23      0.974          1      0.995       0.83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      40/50         0G     0.5107     0.7232     0.9317         10        640: 100%|██████████| 11/11 [02:20<00:00, 12.73s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:04<00:00,  4.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         23         23      0.976          1      0.995      0.823\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      41/50         0G     0.4455     0.9068     0.8763          5        640: 100%|██████████| 11/11 [02:18<00:00, 12.64s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:04<00:00,  4.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         23         23      0.977          1      0.995      0.828\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      42/50         0G     0.4462     0.9395      0.856          5        640: 100%|██████████| 11/11 [02:20<00:00, 12.75s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:04<00:00,  4.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         23         23       0.98          1      0.995       0.82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      43/50         0G     0.4118      0.873     0.8402          5        640: 100%|██████████| 11/11 [02:19<00:00, 12.64s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:04<00:00,  4.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         23         23      0.961          1      0.995      0.815\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      44/50         0G     0.3831     0.8314     0.8362          5        640: 100%|██████████| 11/11 [02:26<00:00, 13.36s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:05<00:00,  5.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         23         23      0.972          1      0.995      0.803\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      45/50         0G      0.375     0.8085     0.8399          5        640: 100%|██████████| 11/11 [02:20<00:00, 12.74s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:04<00:00,  4.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         23         23      0.976          1      0.995      0.825\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      46/50         0G     0.3794     0.8052     0.8303          5        640: 100%|██████████| 11/11 [02:19<00:00, 12.69s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:04<00:00,  4.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         23         23      0.976          1      0.995      0.819\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      47/50         0G     0.3711     0.8042     0.8072          5        640: 100%|██████████| 11/11 [02:20<00:00, 12.79s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:04<00:00,  4.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         23         23      0.978          1      0.995      0.818\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      48/50         0G     0.3737     0.7858     0.8461          5        640: 100%|██████████| 11/11 [02:17<00:00, 12.54s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:04<00:00,  4.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         23         23       0.98          1      0.995      0.817\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      49/50         0G     0.3403      0.765     0.8157          5        640: 100%|██████████| 11/11 [02:17<00:00, 12.50s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:04<00:00,  4.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         23         23       0.98          1      0.995      0.809\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      50/50         0G     0.3481     0.7818     0.8083          5        640: 100%|██████████| 11/11 [02:18<00:00, 12.59s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:04<00:00,  4.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         23         23       0.98          1      0.995      0.815\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "50 epochs completed in 2.027 hours.\n",
      "Optimizer stripped from runs\\detect\\train11\\weights\\last.pt, 6.2MB\n",
      "Optimizer stripped from runs\\detect\\train11\\weights\\best.pt, 6.2MB\n",
      "\n",
      "Validating runs\\detect\\train11\\weights\\best.pt...\n",
      "Ultralytics 8.3.48  Python-3.11.0 torch-2.2.2+cpu CPU (Intel Core(TM) i5-7200U 2.50GHz)\n",
      "Model summary (fused): 168 layers, 3,007,013 parameters, 0 gradients, 8.1 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:04<00:00,  4.38s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         23         23      0.955          1      0.995      0.844\n",
      "                    hi          4          4       0.95          1      0.995      0.945\n",
      "                  left          1          1      0.908          1      0.995      0.895\n",
      "                 right          6          6      0.967          1      0.995      0.799\n",
      "                  stop          4          4      0.952          1      0.995      0.779\n",
      "                    up          2          2      0.988          1      0.995      0.796\n",
      "                  zero          6          6      0.967          1      0.995      0.846\n",
      "Speed: 2.8ms preprocess, 162.6ms inference, 0.0ms loss, 4.5ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\detect\\train11\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# Load YOLOv8 model\n",
    "model = YOLO(\"yolov8n.pt\")  # YOLOv8 Nano model for low-resource training\n",
    "\n",
    "# Train the model on COCO dataset\n",
    "model.train(\n",
    "    data=\"data.yaml\",  # Path to your YAML configuration\n",
    "    epochs=50,                     # Number of training epochs\n",
    "    imgsz=640,                     # Image size\n",
    "    batch=16,                      # Batch size\n",
    "    workers=4,                     # Data loading workers\n",
    "\n",
    ")\n",
    "\n",
    "# Save the model\n",
    "model.save(\"trained_model.pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 340.3ms\n",
      "Speed: 10.0ms preprocess, 340.3ms inference, 8.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 stop, 426.1ms\n",
      "Speed: 5.0ms preprocess, 426.1ms inference, 8.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detected class: stop\n",
      "\n",
      "0: 480x640 1 stop, 329.1ms\n",
      "Speed: 10.0ms preprocess, 329.1ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detected class: stop\n",
      "\n",
      "0: 480x640 1 stop, 282.2ms\n",
      "Speed: 3.0ms preprocess, 282.2ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detected class: stop\n",
      "\n",
      "0: 480x640 1 stop, 280.2ms\n",
      "Speed: 3.0ms preprocess, 280.2ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detected class: stop\n",
      "\n",
      "0: 480x640 (no detections), 276.3ms\n",
      "Speed: 3.0ms preprocess, 276.3ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 248.9ms\n",
      "Speed: 6.0ms preprocess, 248.9ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 zero, 227.9ms\n",
      "Speed: 5.0ms preprocess, 227.9ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detected class: zero\n",
      "\n",
      "0: 480x640 (no detections), 232.4ms\n",
      "Speed: 5.0ms preprocess, 232.4ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 stop, 233.4ms\n",
      "Speed: 4.0ms preprocess, 233.4ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detected class: stop\n",
      "\n",
      "0: 480x640 1 hi, 1 stop, 292.8ms\n",
      "Speed: 5.0ms preprocess, 292.8ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detected class: hi\n",
      "\n",
      "0: 480x640 1 stop, 311.2ms\n",
      "Speed: 11.0ms preprocess, 311.2ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detected class: stop\n",
      "\n",
      "0: 480x640 1 stop, 231.6ms\n",
      "Speed: 3.0ms preprocess, 231.6ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detected class: stop\n",
      "\n",
      "0: 480x640 1 stop, 248.3ms\n",
      "Speed: 8.0ms preprocess, 248.3ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detected class: stop\n",
      "\n",
      "0: 480x640 1 hi, 1 stop, 259.3ms\n",
      "Speed: 3.0ms preprocess, 259.3ms inference, 6.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detected class: stop\n",
      "\n",
      "0: 480x640 1 hi, 1 stop, 270.3ms\n",
      "Speed: 2.0ms preprocess, 270.3ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detected class: stop\n",
      "\n",
      "0: 480x640 1 hi, 1 stop, 234.4ms\n",
      "Speed: 6.0ms preprocess, 234.4ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detected class: stop\n",
      "\n",
      "0: 480x640 1 stop, 262.4ms\n",
      "Speed: 4.0ms preprocess, 262.4ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detected class: stop\n",
      "\n",
      "0: 480x640 1 stop, 231.4ms\n",
      "Speed: 3.0ms preprocess, 231.4ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detected class: stop\n",
      "\n",
      "0: 480x640 (no detections), 218.4ms\n",
      "Speed: 3.0ms preprocess, 218.4ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 stop, 226.4ms\n",
      "Speed: 4.0ms preprocess, 226.4ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detected class: stop\n",
      "\n",
      "0: 480x640 (no detections), 226.4ms\n",
      "Speed: 2.0ms preprocess, 226.4ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 stop, 228.4ms\n",
      "Speed: 7.0ms preprocess, 228.4ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detected class: stop\n",
      "\n",
      "0: 480x640 (no detections), 225.0ms\n",
      "Speed: 5.0ms preprocess, 225.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 stop, 233.8ms\n",
      "Speed: 3.0ms preprocess, 233.8ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detected class: stop\n",
      "\n",
      "0: 480x640 2 stops, 233.4ms\n",
      "Speed: 4.0ms preprocess, 233.4ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detected class: stop\n",
      "\n",
      "0: 480x640 2 stops, 229.4ms\n",
      "Speed: 3.0ms preprocess, 229.4ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detected class: stop\n",
      "\n",
      "0: 480x640 2 stops, 219.0ms\n",
      "Speed: 2.0ms preprocess, 219.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detected class: stop\n",
      "\n",
      "0: 480x640 (no detections), 249.3ms\n",
      "Speed: 4.0ms preprocess, 249.3ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 246.3ms\n",
      "Speed: 3.0ms preprocess, 246.3ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 223.6ms\n",
      "Speed: 5.0ms preprocess, 223.6ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 212.1ms\n",
      "Speed: 10.0ms preprocess, 212.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 stop, 248.3ms\n",
      "Speed: 3.0ms preprocess, 248.3ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detected class: stop\n",
      "\n",
      "0: 480x640 1 stop, 272.8ms\n",
      "Speed: 4.0ms preprocess, 272.8ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detected class: stop\n",
      "\n",
      "0: 480x640 1 stop, 246.3ms\n",
      "Speed: 3.0ms preprocess, 246.3ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detected class: stop\n",
      "\n",
      "0: 480x640 1 stop, 243.0ms\n",
      "Speed: 4.0ms preprocess, 243.0ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detected class: stop\n",
      "\n",
      "0: 480x640 1 stop, 226.4ms\n",
      "Speed: 3.0ms preprocess, 226.4ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detected class: stop\n",
      "\n",
      "0: 480x640 1 stop, 228.4ms\n",
      "Speed: 3.0ms preprocess, 228.4ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detected class: stop\n",
      "\n",
      "0: 480x640 1 stop, 470.7ms\n",
      "Speed: 5.0ms preprocess, 470.7ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detected class: stop\n",
      "\n",
      "0: 480x640 1 stop, 463.8ms\n",
      "Speed: 8.0ms preprocess, 463.8ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detected class: stop\n",
      "\n",
      "0: 480x640 1 stop, 414.6ms\n",
      "Speed: 5.0ms preprocess, 414.6ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detected class: stop\n",
      "\n",
      "0: 480x640 1 stop, 224.4ms\n",
      "Speed: 4.0ms preprocess, 224.4ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detected class: stop\n",
      "\n",
      "0: 480x640 1 stop, 264.3ms\n",
      "Speed: 3.0ms preprocess, 264.3ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detected class: stop\n",
      "\n",
      "0: 480x640 1 stop, 232.4ms\n",
      "Speed: 3.0ms preprocess, 232.4ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detected class: stop\n",
      "\n",
      "0: 480x640 1 stop, 217.4ms\n",
      "Speed: 3.0ms preprocess, 217.4ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detected class: stop\n",
      "\n",
      "0: 480x640 1 stop, 229.4ms\n",
      "Speed: 3.0ms preprocess, 229.4ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detected class: stop\n",
      "\n",
      "0: 480x640 1 stop, 247.4ms\n",
      "Speed: 3.0ms preprocess, 247.4ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detected class: stop\n",
      "\n",
      "0: 480x640 1 stop, 268.3ms\n",
      "Speed: 2.0ms preprocess, 268.3ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detected class: stop\n",
      "\n",
      "0: 480x640 1 stop, 231.4ms\n",
      "Speed: 2.0ms preprocess, 231.4ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detected class: stop\n",
      "\n",
      "0: 480x640 1 stop, 230.9ms\n",
      "Speed: 3.0ms preprocess, 230.9ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detected class: stop\n",
      "\n",
      "0: 480x640 1 stop, 413.9ms\n",
      "Speed: 3.0ms preprocess, 413.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detected class: stop\n",
      "\n",
      "0: 480x640 1 stop, 243.3ms\n",
      "Speed: 4.0ms preprocess, 243.3ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detected class: stop\n",
      "\n",
      "0: 480x640 (no detections), 221.9ms\n",
      "Speed: 5.0ms preprocess, 221.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 stop, 219.4ms\n",
      "Speed: 3.0ms preprocess, 219.4ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detected class: stop\n",
      "\n",
      "0: 480x640 (no detections), 216.6ms\n",
      "Speed: 3.0ms preprocess, 216.6ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 222.4ms\n",
      "Speed: 4.0ms preprocess, 222.4ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 217.4ms\n",
      "Speed: 6.0ms preprocess, 217.4ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 214.5ms\n",
      "Speed: 9.0ms preprocess, 214.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 217.7ms\n",
      "Speed: 5.0ms preprocess, 217.7ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 214.4ms\n",
      "Speed: 8.0ms preprocess, 214.4ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 218.4ms\n",
      "Speed: 7.0ms preprocess, 218.4ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 stop, 219.9ms\n",
      "Speed: 4.0ms preprocess, 219.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detected class: stop\n",
      "\n",
      "0: 480x640 1 stop, 227.2ms\n",
      "Speed: 3.0ms preprocess, 227.2ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detected class: stop\n",
      "\n",
      "0: 480x640 (no detections), 216.4ms\n",
      "Speed: 3.0ms preprocess, 216.4ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 231.4ms\n",
      "Speed: 4.0ms preprocess, 231.4ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 218.4ms\n",
      "Speed: 6.0ms preprocess, 218.4ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 224.0ms\n",
      "Speed: 5.0ms preprocess, 224.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 270.3ms\n",
      "Speed: 8.0ms preprocess, 270.3ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 332.6ms\n",
      "Speed: 16.0ms preprocess, 332.6ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 stop, 392.9ms\n",
      "Speed: 4.0ms preprocess, 392.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detected class: stop\n",
      "\n",
      "0: 480x640 (no detections), 228.0ms\n",
      "Speed: 3.0ms preprocess, 228.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 263.3ms\n",
      "Speed: 2.0ms preprocess, 263.3ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 stop, 246.8ms\n",
      "Speed: 5.0ms preprocess, 246.8ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detected class: stop\n",
      "\n",
      "0: 480x640 1 stop, 208.4ms\n",
      "Speed: 4.0ms preprocess, 208.4ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detected class: stop\n",
      "\n",
      "0: 480x640 1 stop, 206.4ms\n",
      "Speed: 4.0ms preprocess, 206.4ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detected class: stop\n",
      "\n",
      "0: 480x640 (no detections), 219.1ms\n",
      "Speed: 4.0ms preprocess, 219.1ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 stop, 215.4ms\n",
      "Speed: 5.5ms preprocess, 215.4ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detected class: stop\n",
      "\n",
      "0: 480x640 1 stop, 238.9ms\n",
      "Speed: 2.5ms preprocess, 238.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detected class: stop\n",
      "\n",
      "0: 480x640 1 stop, 1000.3ms\n",
      "Speed: 10.0ms preprocess, 1000.3ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detected class: stop\n",
      "\n",
      "0: 480x640 1 stop, 333.1ms\n",
      "Speed: 9.0ms preprocess, 333.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detected class: stop\n",
      "\n",
      "0: 480x640 1 stop, 311.2ms\n",
      "Speed: 5.0ms preprocess, 311.2ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detected class: stop\n",
      "\n",
      "0: 480x640 1 stop, 352.1ms\n",
      "Speed: 7.0ms preprocess, 352.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detected class: stop\n",
      "\n",
      "0: 480x640 1 stop, 331.1ms\n",
      "Speed: 4.0ms preprocess, 331.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detected class: stop\n",
      "\n",
      "0: 480x640 1 stop, 410.1ms\n",
      "Speed: 4.0ms preprocess, 410.1ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detected class: stop\n",
      "\n",
      "0: 480x640 1 stop, 351.1ms\n",
      "Speed: 12.0ms preprocess, 351.1ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detected class: stop\n",
      "\n",
      "0: 480x640 1 stop, 366.6ms\n",
      "Speed: 7.0ms preprocess, 366.6ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detected class: stop\n",
      "\n",
      "0: 480x640 1 stop, 408.6ms\n",
      "Speed: 4.0ms preprocess, 408.6ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detected class: stop\n",
      "\n",
      "0: 480x640 1 stop, 430.9ms\n",
      "Speed: 9.0ms preprocess, 430.9ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detected class: stop\n",
      "\n",
      "0: 480x640 1 stop, 316.7ms\n",
      "Speed: 3.0ms preprocess, 316.7ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detected class: stop\n",
      "\n",
      "0: 480x640 (no detections), 346.6ms\n",
      "Speed: 7.0ms preprocess, 346.6ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 305.2ms\n",
      "Speed: 7.0ms preprocess, 305.2ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 286.8ms\n",
      "Speed: 3.0ms preprocess, 286.8ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 379.6ms\n",
      "Speed: 5.0ms preprocess, 379.6ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 281.2ms\n",
      "Speed: 11.0ms preprocess, 281.2ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 325.8ms\n",
      "Speed: 6.0ms preprocess, 325.8ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 315.2ms\n",
      "Speed: 6.0ms preprocess, 315.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 282.2ms\n",
      "Speed: 14.0ms preprocess, 282.2ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 506.3ms\n",
      "Speed: 3.0ms preprocess, 506.3ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 212.4ms\n",
      "Speed: 4.0ms preprocess, 212.4ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 219.4ms\n",
      "Speed: 3.0ms preprocess, 219.4ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 229.4ms\n",
      "Speed: 3.0ms preprocess, 229.4ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 244.9ms\n",
      "Speed: 3.0ms preprocess, 244.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 213.4ms\n",
      "Speed: 3.0ms preprocess, 213.4ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 171.5ms\n",
      "Speed: 4.0ms preprocess, 171.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 173.5ms\n",
      "Speed: 3.0ms preprocess, 173.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 176.7ms\n",
      "Speed: 3.4ms preprocess, 176.7ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 174.5ms\n",
      "Speed: 2.0ms preprocess, 174.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 172.5ms\n",
      "Speed: 3.0ms preprocess, 172.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 180.1ms\n",
      "Speed: 2.0ms preprocess, 180.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 178.1ms\n",
      "Speed: 3.0ms preprocess, 178.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 stop, 174.5ms\n",
      "Speed: 3.0ms preprocess, 174.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detected class: stop\n",
      "\n",
      "0: 480x640 (no detections), 173.1ms\n",
      "Speed: 3.0ms preprocess, 173.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 170.5ms\n",
      "Speed: 4.0ms preprocess, 170.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 stop, 173.5ms\n",
      "Speed: 4.0ms preprocess, 173.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detected class: stop\n",
      "\n",
      "0: 480x640 (no detections), 176.5ms\n",
      "Speed: 3.0ms preprocess, 176.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 183.6ms\n",
      "Speed: 4.0ms preprocess, 183.6ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 177.5ms\n",
      "Speed: 3.0ms preprocess, 177.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 174.5ms\n",
      "Speed: 3.0ms preprocess, 174.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 175.5ms\n",
      "Speed: 3.0ms preprocess, 175.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 zero, 189.5ms\n",
      "Speed: 3.0ms preprocess, 189.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detected class: zero\n",
      "\n",
      "0: 480x640 (no detections), 214.7ms\n",
      "Speed: 3.0ms preprocess, 214.7ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 hi, 188.5ms\n",
      "Speed: 3.0ms preprocess, 188.5ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detected class: hi\n",
      "\n",
      "0: 480x640 (no detections), 401.1ms\n",
      "Speed: 94.8ms preprocess, 401.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 stop, 359.0ms\n",
      "Speed: 3.0ms preprocess, 359.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detected class: stop\n",
      "\n",
      "0: 480x640 1 stop, 376.0ms\n",
      "Speed: 4.0ms preprocess, 376.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detected class: stop\n",
      "\n",
      "0: 480x640 1 stop, 271.3ms\n",
      "Speed: 4.0ms preprocess, 271.3ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detected class: stop\n",
      "\n",
      "0: 480x640 1 stop, 255.3ms\n",
      "Speed: 3.0ms preprocess, 255.3ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detected class: stop\n",
      "\n",
      "0: 480x640 1 stop, 244.7ms\n",
      "Speed: 3.0ms preprocess, 244.7ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detected class: stop\n",
      "\n",
      "0: 480x640 1 stop, 414.9ms\n",
      "Speed: 4.0ms preprocess, 414.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detected class: stop\n",
      "\n",
      "0: 480x640 1 stop, 278.3ms\n",
      "Speed: 3.0ms preprocess, 278.3ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detected class: stop\n",
      "\n",
      "0: 480x640 1 stop, 244.3ms\n",
      "Speed: 3.0ms preprocess, 244.3ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detected class: stop\n",
      "\n",
      "0: 480x640 1 stop, 278.3ms\n",
      "Speed: 3.0ms preprocess, 278.3ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detected class: stop\n",
      "\n",
      "0: 480x640 1 stop, 243.6ms\n",
      "Speed: 4.0ms preprocess, 243.6ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detected class: stop\n",
      "\n",
      "0: 480x640 1 stop, 231.4ms\n",
      "Speed: 4.0ms preprocess, 231.4ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detected class: stop\n",
      "\n",
      "0: 480x640 1 stop, 273.3ms\n",
      "Speed: 3.0ms preprocess, 273.3ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detected class: stop\n",
      "\n",
      "0: 480x640 1 stop, 266.6ms\n",
      "Speed: 4.0ms preprocess, 266.6ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detected class: stop\n",
      "\n",
      "0: 480x640 1 stop, 261.3ms\n",
      "Speed: 4.0ms preprocess, 261.3ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detected class: stop\n",
      "\n",
      "0: 480x640 1 stop, 204.5ms\n",
      "Speed: 4.0ms preprocess, 204.5ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detected class: stop\n",
      "\n",
      "0: 480x640 1 stop, 253.3ms\n",
      "Speed: 2.0ms preprocess, 253.3ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detected class: stop\n",
      "\n",
      "0: 480x640 1 stop, 208.4ms\n",
      "Speed: 4.0ms preprocess, 208.4ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detected class: stop\n",
      "\n",
      "0: 480x640 1 stop, 189.5ms\n",
      "Speed: 4.0ms preprocess, 189.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detected class: stop\n",
      "\n",
      "0: 480x640 1 stop, 192.0ms\n",
      "Speed: 3.0ms preprocess, 192.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detected class: stop\n",
      "\n",
      "0: 480x640 (no detections), 175.5ms\n",
      "Speed: 3.0ms preprocess, 175.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 178.1ms\n",
      "Speed: 3.0ms preprocess, 178.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 hi, 177.5ms\n",
      "Speed: 3.0ms preprocess, 177.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detected class: hi\n",
      "\n",
      "0: 480x640 (no detections), 194.5ms\n",
      "Speed: 3.0ms preprocess, 194.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 hi, 177.5ms\n",
      "Speed: 3.0ms preprocess, 177.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detected class: hi\n",
      "\n",
      "0: 480x640 1 hi, 175.5ms\n",
      "Speed: 2.0ms preprocess, 175.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detected class: hi\n",
      "\n",
      "0: 480x640 1 hi, 185.1ms\n",
      "Speed: 4.0ms preprocess, 185.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detected class: hi\n",
      "\n",
      "0: 480x640 1 hi, 174.7ms\n",
      "Speed: 3.0ms preprocess, 174.7ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detected class: hi\n",
      "\n",
      "0: 480x640 1 hi, 173.1ms\n",
      "Speed: 3.0ms preprocess, 173.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detected class: hi\n",
      "\n",
      "0: 480x640 1 hi, 176.5ms\n",
      "Speed: 4.0ms preprocess, 176.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detected class: hi\n",
      "\n",
      "0: 480x640 1 hi, 176.5ms\n",
      "Speed: 3.0ms preprocess, 176.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detected class: hi\n",
      "\n",
      "0: 480x640 1 hi, 177.1ms\n",
      "Speed: 4.0ms preprocess, 177.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detected class: hi\n",
      "\n",
      "0: 480x640 1 hi, 179.9ms\n",
      "Speed: 3.0ms preprocess, 179.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detected class: hi\n",
      "\n",
      "0: 480x640 1 hi, 187.5ms\n",
      "Speed: 3.0ms preprocess, 187.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detected class: hi\n",
      "\n",
      "0: 480x640 1 stop, 173.1ms\n",
      "Speed: 3.0ms preprocess, 173.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detected class: stop\n",
      "\n",
      "0: 480x640 1 stop, 181.5ms\n",
      "Speed: 2.0ms preprocess, 181.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detected class: stop\n",
      "\n",
      "0: 480x640 1 stop, 174.2ms\n",
      "Speed: 3.0ms preprocess, 174.2ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detected class: stop\n",
      "\n",
      "0: 480x640 1 stop, 176.5ms\n",
      "Speed: 3.0ms preprocess, 176.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detected class: stop\n",
      "\n",
      "0: 480x640 1 stop, 181.5ms\n",
      "Speed: 3.0ms preprocess, 181.5ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detected class: stop\n",
      "\n",
      "0: 480x640 1 stop, 172.5ms\n",
      "Speed: 4.0ms preprocess, 172.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detected class: stop\n",
      "\n",
      "0: 480x640 1 stop, 174.1ms\n",
      "Speed: 3.0ms preprocess, 174.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detected class: stop\n",
      "\n",
      "0: 480x640 (no detections), 176.5ms\n",
      "Speed: 4.0ms preprocess, 176.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 175.1ms\n",
      "Speed: 4.0ms preprocess, 175.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 stop, 212.4ms\n",
      "Speed: 3.0ms preprocess, 212.4ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detected class: stop\n",
      "\n",
      "0: 480x640 1 stop, 200.5ms\n",
      "Speed: 3.0ms preprocess, 200.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detected class: stop\n",
      "\n",
      "0: 480x640 1 stop, 176.5ms\n",
      "Speed: 4.0ms preprocess, 176.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detected class: stop\n",
      "\n",
      "0: 480x640 1 stop, 178.5ms\n",
      "Speed: 3.0ms preprocess, 178.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detected class: stop\n",
      "\n",
      "0: 480x640 1 stop, 174.0ms\n",
      "Speed: 3.0ms preprocess, 174.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detected class: stop\n",
      "\n",
      "0: 480x640 2 stops, 177.1ms\n",
      "Speed: 3.0ms preprocess, 177.1ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detected class: stop\n",
      "\n",
      "0: 480x640 2 stops, 186.5ms\n",
      "Speed: 3.0ms preprocess, 186.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detected class: stop\n",
      "\n",
      "0: 480x640 1 stop, 177.7ms\n",
      "Speed: 4.0ms preprocess, 177.7ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detected class: stop\n",
      "\n",
      "0: 480x640 1 stop, 176.5ms\n",
      "Speed: 3.0ms preprocess, 176.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detected class: stop\n",
      "\n",
      "0: 480x640 1 stop, 177.5ms\n",
      "Speed: 3.0ms preprocess, 177.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detected class: stop\n",
      "\n",
      "0: 480x640 1 stop, 175.5ms\n",
      "Speed: 3.0ms preprocess, 175.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detected class: stop\n",
      "\n",
      "0: 480x640 1 stop, 194.0ms\n",
      "Speed: 5.0ms preprocess, 194.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detected class: stop\n",
      "\n",
      "0: 480x640 1 stop, 177.5ms\n",
      "Speed: 3.0ms preprocess, 177.5ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detected class: stop\n",
      "\n",
      "0: 480x640 1 stop, 178.5ms\n",
      "Speed: 3.0ms preprocess, 178.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detected class: stop\n",
      "\n",
      "0: 480x640 1 hi, 176.2ms\n",
      "Speed: 3.0ms preprocess, 176.2ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detected class: hi\n",
      "\n",
      "0: 480x640 1 hi, 178.5ms\n",
      "Speed: 3.0ms preprocess, 178.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detected class: hi\n",
      "\n",
      "0: 480x640 1 hi, 178.1ms\n",
      "Speed: 3.0ms preprocess, 178.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detected class: hi\n",
      "\n",
      "0: 480x640 (no detections), 182.5ms\n",
      "Speed: 3.0ms preprocess, 182.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 185.7ms\n",
      "Speed: 2.0ms preprocess, 185.7ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 191.5ms\n",
      "Speed: 2.0ms preprocess, 191.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 187.5ms\n",
      "Speed: 3.0ms preprocess, 187.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 192.0ms\n",
      "Speed: 4.0ms preprocess, 192.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 189.5ms\n",
      "Speed: 6.0ms preprocess, 189.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 179.8ms\n",
      "Speed: 4.0ms preprocess, 179.8ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 186.5ms\n",
      "Speed: 3.5ms preprocess, 186.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 176.5ms\n",
      "Speed: 4.0ms preprocess, 176.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 183.5ms\n",
      "Speed: 3.0ms preprocess, 183.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 188.5ms\n",
      "Speed: 3.0ms preprocess, 188.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 189.4ms\n",
      "Speed: 2.0ms preprocess, 189.4ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 182.5ms\n",
      "Speed: 6.0ms preprocess, 182.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 187.5ms\n",
      "Speed: 4.0ms preprocess, 187.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 191.5ms\n",
      "Speed: 2.0ms preprocess, 191.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 190.5ms\n",
      "Speed: 4.0ms preprocess, 190.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 206.0ms\n",
      "Speed: 3.0ms preprocess, 206.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 197.5ms\n",
      "Speed: 3.0ms preprocess, 197.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 225.4ms\n",
      "Speed: 3.0ms preprocess, 225.4ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 186.5ms\n",
      "Speed: 3.0ms preprocess, 186.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 189.5ms\n",
      "Speed: 3.0ms preprocess, 189.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 180.7ms\n",
      "Speed: 4.0ms preprocess, 180.7ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 204.5ms\n",
      "Speed: 11.0ms preprocess, 204.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 236.3ms\n",
      "Speed: 9.0ms preprocess, 236.3ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 181.7ms\n",
      "Speed: 2.0ms preprocess, 181.7ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 223.4ms\n",
      "Speed: 3.0ms preprocess, 223.4ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 186.5ms\n",
      "Speed: 3.0ms preprocess, 186.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 193.5ms\n",
      "Speed: 3.0ms preprocess, 193.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 192.0ms\n",
      "Speed: 3.0ms preprocess, 192.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 185.7ms\n",
      "Speed: 4.0ms preprocess, 185.7ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 182.5ms\n",
      "Speed: 3.0ms preprocess, 182.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 178.5ms\n",
      "Speed: 3.0ms preprocess, 178.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 176.5ms\n",
      "Speed: 2.0ms preprocess, 176.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 169.1ms\n",
      "Speed: 4.0ms preprocess, 169.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 173.8ms\n",
      "Speed: 3.0ms preprocess, 173.8ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 186.1ms\n",
      "Speed: 3.0ms preprocess, 186.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 178.5ms\n",
      "Speed: 3.0ms preprocess, 178.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 177.5ms\n",
      "Speed: 2.0ms preprocess, 177.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 209.7ms\n",
      "Speed: 27.9ms preprocess, 209.7ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 278.2ms\n",
      "Speed: 8.0ms preprocess, 278.2ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 195.5ms\n",
      "Speed: 2.0ms preprocess, 195.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 226.9ms\n",
      "Speed: 4.0ms preprocess, 226.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 197.6ms\n",
      "Speed: 2.0ms preprocess, 197.6ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 194.5ms\n",
      "Speed: 2.0ms preprocess, 194.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 190.5ms\n",
      "Speed: 4.0ms preprocess, 190.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 194.0ms\n",
      "Speed: 5.0ms preprocess, 194.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 195.3ms\n",
      "Speed: 3.0ms preprocess, 195.3ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 189.0ms\n",
      "Speed: 3.0ms preprocess, 189.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 208.4ms\n",
      "Speed: 3.0ms preprocess, 208.4ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 196.5ms\n",
      "Speed: 4.0ms preprocess, 196.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 185.5ms\n",
      "Speed: 3.0ms preprocess, 185.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 196.7ms\n",
      "Speed: 2.0ms preprocess, 196.7ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 182.5ms\n",
      "Speed: 3.0ms preprocess, 182.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 189.5ms\n",
      "Speed: 3.0ms preprocess, 189.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 198.5ms\n",
      "Speed: 4.0ms preprocess, 198.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 237.4ms\n",
      "Speed: 3.0ms preprocess, 237.4ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 183.1ms\n",
      "Speed: 3.0ms preprocess, 183.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 191.0ms\n",
      "Speed: 2.0ms preprocess, 191.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 537.8ms\n",
      "Speed: 3.0ms preprocess, 537.8ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 292.6ms\n",
      "Speed: 29.9ms preprocess, 292.6ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 353.1ms\n",
      "Speed: 6.0ms preprocess, 353.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 300.2ms\n",
      "Speed: 15.0ms preprocess, 300.2ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 261.7ms\n",
      "Speed: 4.0ms preprocess, 261.7ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 273.3ms\n",
      "Speed: 5.0ms preprocess, 273.3ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 283.8ms\n",
      "Speed: 2.0ms preprocess, 283.8ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 257.3ms\n",
      "Speed: 11.0ms preprocess, 257.3ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 246.3ms\n",
      "Speed: 3.0ms preprocess, 246.3ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 260.0ms\n",
      "Speed: 3.0ms preprocess, 260.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 290.0ms\n",
      "Speed: 4.0ms preprocess, 290.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 276.3ms\n",
      "Speed: 10.0ms preprocess, 276.3ms inference, 5.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 397.9ms\n",
      "Speed: 5.0ms preprocess, 397.9ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 227.4ms\n",
      "Speed: 9.0ms preprocess, 227.4ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 269.8ms\n",
      "Speed: 3.0ms preprocess, 269.8ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 282.2ms\n",
      "Speed: 3.0ms preprocess, 282.2ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 308.2ms\n",
      "Speed: 2.0ms preprocess, 308.2ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 370.7ms\n",
      "Speed: 7.9ms preprocess, 370.7ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 228.8ms\n",
      "Speed: 3.0ms preprocess, 228.8ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 235.6ms\n",
      "Speed: 3.0ms preprocess, 235.6ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 912.1ms\n",
      "Speed: 4.0ms preprocess, 912.1ms inference, 5.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 614.4ms\n",
      "Speed: 7.0ms preprocess, 614.4ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 291.2ms\n",
      "Speed: 6.0ms preprocess, 291.2ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 309.2ms\n",
      "Speed: 4.0ms preprocess, 309.2ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 285.2ms\n",
      "Speed: 3.5ms preprocess, 285.2ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 249.9ms\n",
      "Speed: 3.0ms preprocess, 249.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 300.2ms\n",
      "Speed: 3.0ms preprocess, 300.2ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 307.4ms\n",
      "Speed: 7.0ms preprocess, 307.4ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 298.2ms\n",
      "Speed: 6.0ms preprocess, 298.2ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 226.4ms\n",
      "Speed: 6.0ms preprocess, 226.4ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 207.5ms\n",
      "Speed: 3.0ms preprocess, 207.5ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 210.4ms\n",
      "Speed: 4.0ms preprocess, 210.4ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 205.4ms\n",
      "Speed: 3.0ms preprocess, 205.4ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 201.5ms\n",
      "Speed: 4.0ms preprocess, 201.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 206.4ms\n",
      "Speed: 3.0ms preprocess, 206.4ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 202.9ms\n",
      "Speed: 4.0ms preprocess, 202.9ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 201.5ms\n",
      "Speed: 3.0ms preprocess, 201.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 240.4ms\n",
      "Speed: 4.0ms preprocess, 240.4ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 205.4ms\n",
      "Speed: 2.0ms preprocess, 205.4ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 202.5ms\n",
      "Speed: 4.0ms preprocess, 202.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 207.4ms\n",
      "Speed: 3.0ms preprocess, 207.4ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 218.4ms\n",
      "Speed: 5.0ms preprocess, 218.4ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 205.4ms\n",
      "Speed: 3.0ms preprocess, 205.4ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 205.4ms\n",
      "Speed: 2.0ms preprocess, 205.4ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 211.6ms\n",
      "Speed: 2.0ms preprocess, 211.6ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 286.2ms\n",
      "Speed: 5.0ms preprocess, 286.2ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 262.3ms\n",
      "Speed: 3.0ms preprocess, 262.3ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import pyautogui\n",
    "from ultralytics import YOLO\n",
    "import time\n",
    "\n",
    "# Load the trained YOLO model\n",
    "model = YOLO(\"trained_model.pt\")  # Replace with your .pt file path\n",
    "\n",
    "# Define action mappings for gestures\n",
    "gesture_to_action = {\n",
    "    \"left\": lambda: pyautogui.press(\"left\"),\n",
    "    \"right\": lambda: pyautogui.press(\"right\"),\n",
    "    \"up\": lambda: pyautogui.press(\"up\"),\n",
    "    \"down\": lambda: pyautogui.press(\"down\"),\n",
    "    \"hi\": lambda: pyautogui.doubleClick(),  # Perform a double left-click\n",
    "    # \"stop\" will be handled separately for relative cursor movement\n",
    "}\n",
    "\n",
    "# Cooldown mechanism (applied only to specific gestures)\n",
    "last_action_time = {}\n",
    "cooldown_period = 2  # Cooldown period in seconds for each gesture (excluding \"hi\")\n",
    "\n",
    "# Open video capture (webcam)\n",
    "cap = cv2.VideoCapture(0)  # Use 0 for the default webcam, or provide a video file path\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"Failed to grab frame. Exiting...\")\n",
    "        break\n",
    "\n",
    "    # Flip the frame horizontally\n",
    "    frame = cv2.flip(frame, 1)\n",
    "\n",
    "    # Make predictions\n",
    "    results = model.predict(frame, imgsz=640, conf=0.5)  # Adjust confidence threshold if needed\n",
    "\n",
    "    # Extract detected class names and bounding boxes\n",
    "    detected_classes = []\n",
    "    detected_boxes = []\n",
    "    for result in results:\n",
    "        for box in result.boxes:\n",
    "            cls_idx = int(box.cls.cpu().numpy())  # Class index\n",
    "            cls_name = model.names[cls_idx]  # Get class name\n",
    "            detected_classes.append(cls_name)\n",
    "            detected_boxes.append(box.xyxy.cpu().numpy()[0])  # Bounding box coordinates (x1, y1, x2, y2)\n",
    "\n",
    "    if detected_classes:\n",
    "        detected_class = detected_classes[0]  # Use the first detected gesture\n",
    "        detected_box = detected_boxes[0]  # Bounding box of the first detected gesture\n",
    "        print(f\"Detected class: {detected_class}\")\n",
    "\n",
    "        # Handle \"hi\" gesture for relative cursor movement (no cooldown applied)\n",
    "        if detected_class == \"stop\":\n",
    "            x1, y1, x2, y2 = detected_box\n",
    "            box_center_x = (x1 + x2) / 2\n",
    "            box_center_y = (y1 + y2) / 2\n",
    "\n",
    "            # Calculate movement offset relative to frame center\n",
    "            frame_center_x = frame.shape[1] / 2\n",
    "            frame_center_y = frame.shape[0] / 2\n",
    "\n",
    "            # Increase the scaling factor to speed up cursor movement\n",
    "            speed_factor = 0.5  # Adjust this value to control the speed\n",
    "            move_x = int((box_center_x - frame_center_x) * speed_factor)\n",
    "            move_y = int((box_center_y - frame_center_y) * speed_factor)\n",
    "\n",
    "            # Move cursor relative to its current position\n",
    "            pyautogui.moveRel(move_x, move_y)\n",
    "\n",
    "        # Apply cooldown to other gestures\n",
    "        elif detected_class in gesture_to_action:\n",
    "            current_time = time.time()\n",
    "            if detected_class not in last_action_time or (current_time - last_action_time[detected_class]) > cooldown_period:\n",
    "                gesture_to_action[detected_class]()  # Perform the mapped action\n",
    "                last_action_time[detected_class] = current_time  # Update the last action time\n",
    "\n",
    "    # Draw bounding boxes and labels on the frame\n",
    "    annotated_frame = results[0].plot() if results else frame\n",
    "\n",
    "    # Display the frame\n",
    "    cv2.imshow(\"Real-Time Detection\", annotated_frame)\n",
    "\n",
    "    # Break loop on 'q' key press\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release resources\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
